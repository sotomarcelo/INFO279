{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9801d18e",
   "metadata": {},
   "source": [
    "# 3. Análisis de tópicos con LDA (Latent Dirichlet Allocation)\n",
    "\n",
    "## 3.1 Motivación\n",
    "\n",
    "El __análisis de tópicos__ permite descubrir, a partir de los propios textos, el conjunto de tópicos que estos abordan. Se trata de un análisis automatizado, que podría ser difícil de llevar a cabo manualmente, debido a la cantidad de textos.\n",
    "\n",
    "Uno de los algoritmos más comunes para analizar tópicos es el algoritmo _Latent Dirichlet Allocation (LDA)_ (Artículo \"Latent Dirichlet Allocation\" : https://drive.google.com/file/d/1BobImO3192hifZPLXowd14gryVAUzBPW/view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee291e2",
   "metadata": {},
   "source": [
    "__¿Qué hace LDA?__\n",
    "\n",
    "Dado un número de tópicos definido por el analista, el modelo permite asociar una distribución de tópicos $\\theta_d$ a cada texto $d$ y al mismo tiempo, la distribución de palabras $\\beta_t$ en cada tópico $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c995b5",
   "metadata": {},
   "source": [
    "<img src=\"img/f1.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aeaf36",
   "metadata": {},
   "source": [
    "<img src=\"img/f2.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b56ef",
   "metadata": {},
   "source": [
    "## 3.2 ¿Cómo hacer un análisis de tópicos en Python?\n",
    "\n",
    "En este tutorial, tomaremos un dataset de noticias de prensa en español del mes de febrero 2021 y utilizaremos LDA para descubrir cuáles son los tópicos de las noticias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2072ba9d",
   "metadata": {},
   "source": [
    "### 3.2.1 Cargar el dataset de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8eed47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# leer el archivo CSV\n",
    "archivo = \"./data/catrillanca.csv\"\n",
    "corpus = pandas.read_csv(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53be9cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id_news</th>\n",
       "      <th>country</th>\n",
       "      <th>media_outlet</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>243393.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>horas24</td>\n",
       "      <td>https://www.24horas.cl/nacional/instituto-naci...</td>\n",
       "      <td>Instituto Nacional de Derechos Humanos amplía ...</td>\n",
       "      <td>El Instituto Nacional de Derechos Humanos (IND...</td>\n",
       "      <td>2019-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5163425.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>ahoranoticiasmega</td>\n",
       "      <td>https://www.meganoticias.cl/nacional/268476-pa...</td>\n",
       "      <td>Padre de Catrillanca solicita presencia de Bac...</td>\n",
       "      <td>Hasta el Palacio de la Moneda llegó Marcelo Ca...</td>\n",
       "      <td>2019-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13829736.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>emol</td>\n",
       "      <td>https://www.emol.com/noticias/Nacional/2019/03...</td>\n",
       "      <td>Adolescente que acompañaba a Catrillanca: \"Hab...</td>\n",
       "      <td>SANTIAGO.- A casi cuatro meses de la muerte de...</td>\n",
       "      <td>2019-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5439896.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>ahoranoticiasmega</td>\n",
       "      <td>https://www.meganoticias.cl/nacional/245535-ca...</td>\n",
       "      <td>Cartas enviadas a familia de Camilo Catrillanc...</td>\n",
       "      <td>Hace unos días Marcelo Catrillanca, padre de C...</td>\n",
       "      <td>2018-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5442943.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>ahoranoticiasmega</td>\n",
       "      <td>https://www.meganoticias.cl/nacional/245302-ca...</td>\n",
       "      <td>Caso Catrillanca: Comuneros mapuche se toman l...</td>\n",
       "      <td>Durante la mañana de este jueves, un grupo de ...</td>\n",
       "      <td>2018-12-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id_news country       media_outlet  \\\n",
       "0           0    243393.0   chile            horas24   \n",
       "1           1   5163425.0   chile  ahoranoticiasmega   \n",
       "2           2  13829736.0   chile               emol   \n",
       "3           3   5439896.0   chile  ahoranoticiasmega   \n",
       "4           4   5442943.0   chile  ahoranoticiasmega   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.24horas.cl/nacional/instituto-naci...   \n",
       "1  https://www.meganoticias.cl/nacional/268476-pa...   \n",
       "2  https://www.emol.com/noticias/Nacional/2019/03...   \n",
       "3  https://www.meganoticias.cl/nacional/245535-ca...   \n",
       "4  https://www.meganoticias.cl/nacional/245302-ca...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Instituto Nacional de Derechos Humanos amplía ...   \n",
       "1  Padre de Catrillanca solicita presencia de Bac...   \n",
       "2  Adolescente que acompañaba a Catrillanca: \"Hab...   \n",
       "3  Cartas enviadas a familia de Camilo Catrillanc...   \n",
       "4  Caso Catrillanca: Comuneros mapuche se toman l...   \n",
       "\n",
       "                                                text        date  \n",
       "0  El Instituto Nacional de Derechos Humanos (IND...  2019-06-22  \n",
       "1  Hasta el Palacio de la Moneda llegó Marcelo Ca...  2019-07-17  \n",
       "2  SANTIAGO.- A casi cuatro meses de la muerte de...  2019-03-10  \n",
       "3  Hace unos días Marcelo Catrillanca, padre de C...  2018-12-30  \n",
       "4  Durante la mañana de este jueves, un grupo de ...  2018-12-27  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e10002",
   "metadata": {},
   "source": [
    "- Son 2.931 noticias en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f83e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a940e7dd",
   "metadata": {},
   "source": [
    "- Creamos una lista de noticias a partir del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18801c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias = corpus.text.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8670485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El 14 de noviembre de 2018, en la comuna de Ercilla en la Región de La Araucanía, un grupo de integrantes del Comando Jungla del GOPE de Carabineros asesinó al comunero mapuche de 24 años, Camilo Catrillanca. El crimen se realizó en el contexto de un operativo por un supuesto delito de robo que minutos antes habìa tenido lugar, identificando erradamente los policías a Catrillanca como uno de los participantes en el atraco, disparándole entonces mientras este se encontraba sobre el tractor en el que trabajaba. El joven iba entonces acompañado por su amigo de 15 años de iniciales M.A.P.C., quien fue agredido y torturado por los uniformados. Desde entonces ha pasado un año y el caso se encuentra en manos de la Justicia, la que este próximo 30 de noviembre llevará a cabo la audiencia de juicio oral en contra de los carabineros acusados por el crimen de Camilo. Federico Aguirre, jefe regional de La Araucanía del Instituto Nacional de Derechos Humanos (INDH), querellante en este caso, declaró en el contexto del cumplimiento de un año del asesinato que “el homicidio de Camilo Catrillanca no representa un hecho de violencia aislado, responde a un patrón de vulneraciones graves de Derechos Humanos, de que han sido víctimas integrantes del pueblo mapuche, que no puede quedar en la impunidad”. Sin embargo, el gobierno de Sebastián Piñera no ha asumido nunca la responsabilidad política del crimen del comunero, manteniendo en su cargo al ministro del Interior Andrés Chadwick -quien salió del Ejecutivo recientemente en medio de la crisis que azota a la administración del mandatario-, aún cuando una comisión investigadora de la Cámara de Diputados estableció que tanto él como el subsecretario del Interior, Rodrigo Ubilla, son los responsables políticos del asesinato de Camilo Catrillanca. En este contexto es que para la jornada de este jueves se ha convocado a una serie de movilizaciones a lo largo de todo Chile, esto con el objetivo de mantener viva en la memoria colectiva este homicidio y para exigir justicia por el crimen del joven mapuche. En Santiago, por ejemplo, se realizará una velatón en la Plaza de Armas y una concentración en la Plaza de la Dignidad (Plaza Italia), ambas a las 17:00 horas. En tanto, en Valparaíso se llevará a cabo una concentración en el Congreso Nacional al mediodía y una marcha a las 5 de la tarde desde la Plaza Sotomayor. Acá compartimos un resumen de todas las actividades que tendrán lugar a lo largo de todo Chile. '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias[501]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636a344",
   "metadata": {},
   "source": [
    "### 3.2.2  Instalación de librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c7462e",
   "metadata": {},
   "source": [
    "- Instalamos en nuestra máquina la libreria \"pyLDAvis\" que permite visualizar los resultados del análisis de tópicos \n",
    "\n",
    "Note bene: los comandos \"pip install ..\" solo se hacen una vez para descargar las librerias en su computador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1447967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: numexpr in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.20.3)\n",
      "Requirement already satisfied: future in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp39-cp39-win_amd64.whl (23.9 MB)\n",
      "Requirement already satisfied: joblib in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.24.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pyLDAvis) (58.0.4)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\marce\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marce\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.16.0)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\marce\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\marce\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marce\\anaconda3\\lib\\site-packages (from scikit-learn->pyLDAvis) (2.2.0)\n",
      "Building wheels for collected packages: pyLDAvis, sklearn\n",
      "  Building wheel for pyLDAvis (PEP 517): started\n",
      "  Building wheel for pyLDAvis (PEP 517): finished with status 'done'\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136882 sha256=871f472d4759efbfe57386c0c25884e153af363f947e4d37f97e4f33e3afd3d8\n",
      "  Stored in directory: c:\\users\\marce\\appdata\\local\\pip\\cache\\wheels\\57\\a4\\86\\d10c6c2e0bf149fbc0afb0aa5a6528ac35b30a133a0270c477\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=cfaa43f3f9f7a9bf5415c984c19642b3172bb8ca0c8df22162b28ce8026658d8\n",
      "  Stored in directory: c:\\users\\marce\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built pyLDAvis sklearn\n",
      "Installing collected packages: Cython, sklearn, gensim, funcy, pyLDAvis\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "Successfully installed Cython-0.29.28 funcy-1.17 gensim-4.2.0 pyLDAvis-3.3.1 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0bf96f",
   "metadata": {},
   "source": [
    "- Utilizaremos spacy para procesar textos en español (no es útil instalar la libreria con \"pip instal...\" ya que ya lo hicimos en notebook anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd1e854",
   "metadata": {},
   "source": [
    "- Utilizaremos Gensim (para el análisis de tópicos) y pyLDAvis (para visualizar los tópicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec15196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d572344",
   "metadata": {},
   "source": [
    "### 3.2.3 Preprocesamiento de las noticias\n",
    "\n",
    "Procesaremos todas las noticias para representarlas como una lista de:\n",
    "- sustantivos (NOUN)\n",
    "- y conceptos claves (NOUN-de-NOUN) y (NOUN-ADJ)\n",
    "- entidades (PER) y (ORG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417cc6b5",
   "metadata": {},
   "source": [
    "- Agregamos patrones para buscar conceptos claves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_1 = [{\"POS\": \"NOUN\"},{\"LOWER\": \"de\"}, {\"POS\": \"NOUN\"}]\n",
    "matcher.add(\"NOUN-de-NOUN\", [pattern_1])\n",
    "\n",
    "pattern_2 = [{\"POS\": \"NOUN\"}, {\"POS\": \"ADJ\"}]\n",
    "matcher.add(\"NOUN-ADJ\", [pattern_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80588c",
   "metadata": {},
   "source": [
    "- Definemos una función para preprocesar una noticia y transformarla en una lista de \"palabras\" relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40971308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(noticia):\n",
    "    list_of_words = []\n",
    "    \n",
    "    try:\n",
    "        doc = nlp(noticia)\n",
    "\n",
    "        for token in doc:\n",
    "            if (token.pos_==\"NOUN\"):\n",
    "                list_of_words.append(token.text)\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if (ent.label_ == \"PER\" and \" \" in ent.text):\n",
    "                list_of_words.append(ent.text)\n",
    "\n",
    "        matches = matcher(doc)\n",
    "\n",
    "        for match_id, start, end in matches:\n",
    "            span = doc[start:end]  # The matched span\n",
    "            list_of_words.append(span.text)\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(noticia)\n",
    "        print(e)\n",
    "    \n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f03efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_list(noticias[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60ec52",
   "metadata": {},
   "source": [
    "- Transformamos todas las noticias de nuestro corpus \"noticias\" aplicando la función \"text_to_list\". De cierta manera, simplificará el texto guardando solamente las palabras y conceptos importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de8ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_procesadas = []\n",
    "\n",
    "for index, noticia in enumerate(noticias):\n",
    "    print(index)\n",
    "    noticia_procesada = text_to_list(noticia)\n",
    "    noticias_procesadas.append(noticia_procesada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371a1a9",
   "metadata": {},
   "source": [
    "- Veamos cómo se transformó una cierta noticia. La variable \"N\" representa el rango de la noticia en nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0185950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noticias[N])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedbdc58",
   "metadata": {},
   "source": [
    "- Se simplificó en:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f79cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noticias_procesadas[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65973d6e",
   "metadata": {},
   "source": [
    "### 3.2.4 Preparar los datos de entrada de LDA\n",
    "\n",
    "los datos de entrada de LDA son: \n",
    "- un diccionario (variable 'id2word')\n",
    "- nuestro dataset preprocesado ('noticias_procesadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca456588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(noticias_procesadas)\n",
    "id2word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e454f",
   "metadata": {},
   "source": [
    "- Se asigna una ID a cada palabra (o concepto) del vocabulario. Por ejemplo con el ID=25 corresponde a la palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab5167",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word[179]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = noticias_procesadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ca5f4",
   "metadata": {},
   "source": [
    "- Ahora una noticia se vuelve imposible de leer para un humano. Miremos por ejemplo la noticia N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b4d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [id2word.doc2bow(noticia_procesada) for noticia_procesada in noticias_procesadas]\n",
    "\n",
    "# View\n",
    "print(dataset[:N])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d71962d",
   "metadata": {},
   "source": [
    "### 3.3. Entrenamiento del modelo de tópico con LDA\n",
    "\n",
    "- Entrenaremos un primer modelo de tópicos buscando un modelo con 5 tópicos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b40aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=dataset,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb6cea",
   "metadata": {},
   "source": [
    "- Guardaremos el modelo en el disco duro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0a96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save('./output/lda_model_catrillanca_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd04dd8",
   "metadata": {},
   "source": [
    "### 3.4. Visualizar los tópicos encontrados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c6dd8",
   "metadata": {},
   "source": [
    "- Se puede imprimir los tópicos con sus principales palabras principales..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a82e96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics(num_words=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe18cd",
   "metadata": {},
   "source": [
    "- ... o se puede visualizar mejor con la libreria pyLDAvis\n",
    "\n",
    "Nota bene: el número que identifica los topicos puede cambiar... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28686fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, dataset, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2d683",
   "metadata": {},
   "source": [
    "### 3.5. Calcular las metricas de Perplejidad (_Model Perplexity_) y Coherencia (_Coherence Score_)\n",
    "\n",
    "La perplejidad del modelo y la coherencia del tema proporcionan metricas estadisticas para evaluar que tan revante es un modelo para describir el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(dataset))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=noticias_procesadas, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde15be7",
   "metadata": {},
   "source": [
    "### 3.6. ¿Cómo encontrar cuál es el mejor número de tópicos para describir el dataset?\n",
    "\n",
    "- Queremos encontrar el modelo que optimiza la métrica de coherencia (o minimiza la métrica de perplejidad). Probaremos con distintos valores de número de tópicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfac68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NO CAMBIAR ESTA CELDA###\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        print(num_topics)\n",
    "        \n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=dataset,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        \n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba1b32",
   "metadata": {},
   "source": [
    "- Entrenaremos modelos desde 2 tópicos hasta 15 tópicos con un salto de 2 --> 2, 4, 6, 8, 10, 12, 14\n",
    "\n",
    "Nota bene: Se puede demorar varios minutos (o incluso varias horas según el tamaño del dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d14d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=2\n",
    "limit=15\n",
    "step=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=dataset, texts=noticias_procesadas, start=start, limit=limit, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009fa237",
   "metadata": {},
   "source": [
    "- ¿Cuál modelo conservar? Miraremos la métrica de coherencia..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4012573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3c12a",
   "metadata": {},
   "source": [
    "- Guardaremos el mejor modelo en un archivo para poder reutilizarlo despues sin volver a entrenar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa40ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo='./output/optimal_model_catrillanca_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af24ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model.save(archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fc511",
   "metadata": {},
   "source": [
    "- En cualquier momento, se puede volver a cargar el model desde el archivo, sin volver a entrenar el modelo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ddb461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "optimal_model = LdaModel.load(archivo, mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c4173",
   "metadata": {},
   "source": [
    "- Visualizemos el modelo de tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9771e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(optimal_model, dataset, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4819f",
   "metadata": {},
   "source": [
    "### 8. ¿Cuál es el tópico principal de cada documento?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a6ec7",
   "metadata": {},
   "source": [
    "- Podemos analizar cuál es el tópico principal de cada documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad85a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_documents(ldamodel=None, corpus=corpus, texts=texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_documents(ldamodel=optimal_model, corpus=dataset, texts=noticias)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d281c",
   "metadata": {},
   "source": [
    "- La variable \"df_dominant_topic\" contiene una columna \"Dominant_topic\" que indica el tópico principal en cada documento y cuál su porcentaje (variable \"Topic_Perc_contrib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d438b6",
   "metadata": {},
   "source": [
    "- Añadiremos la columna \"media_outlet\" para saber de qué medio viene cada noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_outlet = corpus.filter(['media_outlet'], axis=1)\n",
    "df_dominant_topic=df_dominant_topic.join(media_outlet)\n",
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb134f3",
   "metadata": {},
   "source": [
    "- Podemos contar cuántos documentos son por tópicos principales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acca40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasql import sqldf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775bd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sqldf(\"SELECT Dominant_Topic, count(*) as nb_noticias FROM df_dominant_topic GROUP BY Dominant_Topic ORDER BY count(*) DESC\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b9105",
   "metadata": {},
   "source": [
    "- ¿Cuál es la noticia más representativa de cada tópcio?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c1299",
   "metadata": {},
   "source": [
    "- Tópico 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15bc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "result = sqldf(\"SELECT * FROM df_dominant_topic WHERE dominant_topic=1.0 ORDER BY Topic_Perc_Contrib DESC LIMIT 1\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b8e65",
   "metadata": {},
   "source": [
    "- Tópico 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "result = sqldf(\"SELECT * FROM df_dominant_topic WHERE dominant_topic=2.0 ORDER BY Topic_Perc_Contrib DESC LIMIT 1\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c32e5f4",
   "metadata": {},
   "source": [
    "- Tópico 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adff3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "result = sqldf(\"SELECT * FROM df_dominant_topic WHERE dominant_topic=5.0 ORDER BY Topic_Perc_Contrib DESC LIMIT 5\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f4171",
   "metadata": {},
   "source": [
    "- Tópico 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "result = sqldf(\"SELECT * FROM df_dominant_topic WHERE dominant_topic=6.0 ORDER BY Topic_Perc_Contrib DESC LIMIT 3\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d290a",
   "metadata": {},
   "source": [
    "- tópico 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "result = sqldf(\"SELECT * FROM df_dominant_topic WHERE dominant_topic=7.0 ORDER BY Topic_Perc_Contrib DESC LIMIT 1\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0de2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias[1943]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04e996",
   "metadata": {},
   "source": [
    "- tópico 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335e0c4",
   "metadata": {},
   "source": [
    "__¿Conclusiones?__\n",
    "\n",
    "- El tópico de \"violaciones/democracia/manifestaciones\" nunca es el tópico central de la noticia que hablan de Catrillanca. Es un tópico al segundo plano.\n",
    "\n",
    "- ...\n",
    "\n",
    "__¿Cómo nombrar los tópicos?__\n",
    "\n",
    "Del más frecuente al menos frecuente...\n",
    "\n",
    "6 --> Consecuencias del caso Catrillanca para el gobierno y sus ministros\n",
    "\n",
    "8 --> Consecuencias judiciales del caso Catrillanca\n",
    "\n",
    "1 --> Relato del caso Catrillanca\n",
    "\n",
    "2 --> Noticias que integran un medio con ruido HTML (video, redes sociales)\n",
    "\n",
    "5 --> Crisis de confianza instituciones Carabiñeros y Fuerzas Armadas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07a6faa",
   "metadata": {},
   "source": [
    "¿Qué medios hablan de crisis de confianza?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "result = sqldf(\"SELECT media_outlet,dominant_topic, count(*) FROM df_dominant_topic GROUP BY media_outlet,dominant_topic ORDER BY media_outlet, count(*) DESC\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fad7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'t0':[],'t1':[],'t2':[],'t3':[],'t4':[],'t5':[],'t6':[],'t7':[],'t8':[],'t9':[]}\n",
    "\n",
    "df_by_media = pd.DataFrame(data)  \n",
    "  \n",
    "df_by_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94a273",
   "metadata": {},
   "outputs": [],
   "source": [
    " for i, row_list in enumerate(optimal_model[dataset]):\n",
    "    \n",
    "    t0=0\n",
    "    t1=0\n",
    "    t2=0\n",
    "    t3=0\n",
    "    t4=0\n",
    "    t5=0\n",
    "    t6=0\n",
    "    t7=0\n",
    "    t8=0\n",
    "    t9=0\n",
    "    \n",
    "    for topic in row_list[0]:\n",
    "        key=topic[0]\n",
    "        value=topic[1]\n",
    "        \n",
    "        if key == 0:\n",
    "            t0 = value\n",
    "        if key == 1:\n",
    "            t1 = value\n",
    "        if key == 2:\n",
    "            t2 = value\n",
    "        if key == 3:\n",
    "            t3 = value\n",
    "        if key == 4:\n",
    "            t4 = value\n",
    "        if key == 5:\n",
    "            t5 = value\n",
    "        if key == 6:\n",
    "            t6 = value\n",
    "        if key == 7:\n",
    "            t7 = value\n",
    "        if key == 8:\n",
    "            t8 = value\n",
    "        if key == 9:\n",
    "            t9 = value\n",
    "            \n",
    "    new_row = {'t0':t0,'t1':t1,'t2':t2,'t3':t3,'t4':t4,'t5':t5,'t6':t6,'t7':t7,'t8':t8,'t9':t9}\n",
    "    df_by_media = df_by_media.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_media=df_by_media.join(media_outlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95593f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "result = sqldf(\"SELECT media_outlet,avg(t0),avg(t1),avg(t2),avg(t3),avg(t4),avg(t5),avg(t6),avg(t7),avg(t8),avg(t9) FROM df_by_media GROUP BY media_outlet ORDER BY media_outlet ASC\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c243dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 16))\n",
    "\n",
    "result=result.drop(['media_outlet'], axis=1)\n",
    "sns.heatmap(result, annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111885f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
